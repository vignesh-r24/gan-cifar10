## Trial 2
### Changes
1. General:
   - Trains for 500 epochs (Trial 1 had 200 epochs)
1. Generator:
   - Replaces LeakyReLU in Trial1 with **ReLU**.
   - Replaces **sigmoid** with **tanh** as the output layer activation function.

### Results
- Epoch 50<br>
   <kbd><img src="gen_images/image_e_50.png"></kbd>

- Epoch 100<br>
   <kbd><img src="gen_images/image_e_100.png"></kbd>

- Epoch 200<br>
   <kbd><img src="gen_images/image_e_200.png"></kbd>

- Epoch 300<br>
   <kbd><img src="gen_images/image_e_300.png"></kbd>

- Epoch 400<br>
   <kbd><img src="gen_images/image_e_400.png"></kbd>

- Epoch 500<br>
   <kbd><img src="gen_images/image_e_500.png"></kbd>
